{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T23:28:52.933174Z",
     "start_time": "2025-06-08T23:28:47.099093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sys import platform\n",
    "\n",
    "from utils import set_seed, create_directory, display_images\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 # OpenCV for image loading\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix # We'll use sklearn's confusion_matrix directly\n",
    "\n",
    "SEED = 111\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ],
   "id": "9771082fcdd0cc74",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T23:28:54.096605Z",
     "start_time": "2025-06-08T23:28:52.937734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download dataset if not available\n",
    "data_path = create_directory(\"data\")\n",
    "import kagglehub\n",
    "\n",
    "# https://github.com/Kaggle/kagglehub/issues/175\n",
    "os.environ['KAGGLEHUB_CACHE'] = data_path\n",
    "# Download latest version\n",
    "utkface_data = kagglehub.dataset_download(\"jangedoo/utkface-new\")\n",
    "\n",
    "# Thanks windows, cant get the full path due to limit\n",
    "utkface_data_path = os.path.join(data_path, \"datasets\", \"jangedoo\", \"utkface-new\", \"versions\", \"1\", \"UTKFace\")\n",
    "if not os.path.isdir(utkface_data_path):\n",
    "    print(f\"path does is not dir: {utkface_data_path}\")\n"
   ],
   "id": "ec157b1d0206e38d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: D:\\ProgrammingTools\\Pycharmprojects\\dlfp_age_task\\data\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T23:28:54.452574Z",
     "start_time": "2025-06-08T23:28:54.300533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pre evaluate dataset\n",
    "def get_img_ages(dataset_path, image_paths, ages):\n",
    "    parsed_files_count = 0\n",
    "    skipped_files_count = 0\n",
    "    for filepath in glob.glob(os.path.join(dataset_path, '*.jpg')):\n",
    "        filename = os.path.basename(filepath)\n",
    "        try:\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) < 2:\n",
    "                skipped_files_count += 1\n",
    "                continue\n",
    "            age = int(parts[0])\n",
    "            if not (0 <= age <= 116):\n",
    "                skipped_files_count += 1\n",
    "                continue\n",
    "            image_paths.append(filepath)\n",
    "            ages.append(age)\n",
    "            parsed_files_count +=1\n",
    "        except (ValueError, IndexError):\n",
    "            skipped_files_count += 1\n",
    "\n",
    "    print(f\"Successfully parsed {parsed_files_count} image files.\")\n",
    "    print(f\"Skipped {skipped_files_count} image files due to parsing issues or invalid data.\")\n",
    "\n",
    "def age_to_class(age):\n",
    "    if age < 18: return 0\n",
    "    elif age <= 40: return 1\n",
    "    elif age <= 60: return 2\n",
    "    else: return 3\n",
    "\n",
    "image_paths_all = []\n",
    "ages_all = []\n",
    "get_img_ages(utkface_data_path, image_paths_all, ages_all)\n",
    "\n",
    "if not image_paths_all:\n",
    "    raise FileNotFoundError(f\"No valid JPG images found or parsed in {utkface_data_path}.\")\n",
    "\n",
    "# Create DF\n",
    "df_all = pd.DataFrame({'image_path': image_paths_all, 'age': ages_all})\n",
    "df_all['age_class'] = df_all['age'].apply(age_to_class)\n",
    "class_names_list = ['<18', '18-40', '41-60', '>60']\n",
    "print(\"Class distribution:\\n\", df_all['age_class'].value_counts(normalize=True).sort_index())\n",
    "\n"
   ],
   "id": "7967d127dbd5bc3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed 23708 image files.\n",
      "Skipped 0 image files due to parsing issues or invalid data.\n",
      "Class distribution:\n",
      " age_class\n",
      "0    0.178547\n",
      "1    0.538510\n",
      "2    0.181837\n",
      "3    0.101105\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T23:28:54.483433Z",
     "start_time": "2025-06-08T23:28:54.464343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "BATCH_SIZE = 32\n",
    "INITIAL_EPOCHS = 15\n",
    "FINE_TUNE_EPOCHS = 10\n",
    "INITIAL_LEARNING_RATE = 1e-3\n",
    "FINE_TUNE_LEARNING_RATE = 1e-5\n",
    "\n",
    "# For denormalizing images for display\n",
    "INV_NORMALIZE_MEAN = [-0.485/0.229, -0.456/0.224, -0.406/0.225]\n",
    "INV_NORMALIZE_STD = [1/0.229, 1/0.224, 1/0.225]\n",
    "\n",
    "class UTKFaceDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['image_path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = int(self.dataframe.iloc[idx]['age_class'])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(df_all, test_size=0.2, random_state=SEED, stratify=df_all['age_class'])\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.15, random_state=SEED, stratify=train_df['age_class'])\n",
    "\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n"
   ],
   "id": "9a9d5d7dbdd044af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 16121\n",
      "Validation samples: 2845\n",
      "Test samples: 4742\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-06-08T23:28:54.494570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "normalize_transform = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "denormalize_transform = transforms.Normalize(mean=INV_NORMALIZE_MEAN, std=INV_NORMALIZE_STD)\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    normalize_transform\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    normalize_transform\n",
    "])\n",
    "\n",
    "train_dataset = UTKFaceDataset(train_df, transform=train_transforms)\n",
    "val_dataset = UTKFaceDataset(val_df, transform=val_test_transforms)\n",
    "test_dataset = UTKFaceDataset(test_df, transform=val_test_transforms)\n",
    "\n",
    "num_workers = 2\n",
    "if platform.system() == \"Windows\":\n",
    "    num_workers = 0\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True if DEVICE.type == 'cuda' else False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True if DEVICE.type == 'cuda' else False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True if DEVICE.type == 'cuda' else False)\n",
    "\n",
    "# Display some augmented training images\n",
    "print(\"\\nDisplaying some augmented training images:\")\n",
    "x_batch_disp, y_batch_disp = next(iter(train_loader))\n",
    "images_to_display = []\n",
    "labels_to_display = []\n",
    "\n",
    "IMG_TO_DISPLAY = 2\n",
    "\n",
    "for i in range(min(x_batch_disp.size(0), IMG_TO_DISPLAY)): # Display up to IMG_TO_DISPLAY images\n",
    "    img_tensor = x_batch_disp[i]\n",
    "    # Denormalize\n",
    "    img_tensor_denorm = denormalize_transform(img_tensor.cpu().clone()) # .cpu().clone() for safety\n",
    "    # Convert to HWC for Matplotlib\n",
    "    img_np = img_tensor_denorm.permute(1, 2, 0).numpy()\n",
    "    # Clip values to [0, 1] just in case of minor floating point issues after denorm\n",
    "    img_np = np.clip(img_np, 0, 1)\n",
    "    images_to_display.append(img_np)\n",
    "    labels_to_display.append(y_batch_disp[i].item())\n",
    "\n",
    "display_images(images_to_display, labels_to_display, class_names=class_names_list, title_prefix=\"Class: \")\n",
    "\n",
    "def imshow(imges):\n",
    "    plt.figure()\n",
    "    for i in range(4):\n",
    "        img = imges[i,0]\n",
    "        img = img / 2 + 0.5 #unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.subplot(1,4,i+1)\n",
    "        plt.imshow(npimg, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "imshow(images)\n",
    "\n",
    "print('Classes are: ')\n",
    "# print('| '.join(f'{classes[labels[j]]:5s} ' for j in range(4)))"
   ],
   "id": "ba405b1f70c36ca0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Displaying some augmented training images:\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Pre-trained ResNet50 from torchvision\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "num_ftrs = model.fc.in_features\n",
    "# CCT\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, NUM_CLASSES)\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "print(model.fc)"
   ],
   "id": "72bac67947754e0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T13:09:38.761387Z",
     "start_time": "2025-06-09T13:09:38.057017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_SAVE_DIR = \"saved_models_pytorch\" # Directory to save models\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_head = optim.Adam(model.fc.parameters(), lr=INITIAL_LEARNING_RATE)\n",
    "scheduler_head = optim.lr_scheduler.ReduceLROnPlateau(optimizer_head, mode='min', factor=0.1, patience=3)\n",
    "\n",
    "# --- Training and Validation Functions (PyTorch specific) ---\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct_predictions += torch.sum(preds == labels.data)\n",
    "        total_samples += labels.size(0)\n",
    "    return running_loss / total_samples, (correct_predictions.double() / total_samples).item()\n",
    "\n",
    "def validate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    all_preds_list = []\n",
    "    all_labels_list = []\n",
    "    all_probs_list = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_predictions += torch.sum(preds == labels.data)\n",
    "            total_samples += labels.size(0)\n",
    "            all_preds_list.extend(preds.cpu().numpy())\n",
    "            all_labels_list.extend(labels.cpu().numpy())\n",
    "            all_probs_list.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
    "    return running_loss / total_samples, (correct_predictions.double() / total_samples).item(), all_labels_list, all_preds_list, all_probs_list\n",
    "\n",
    "# Training Phase 1 Train the Head\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_val_acc = 0.0\n",
    "create_directory(MODEL_SAVE_DIR)\n",
    "best_model_path_head = os.path.join(MODEL_SAVE_DIR, \"resnet50_utkface_head_best_pytorch.pth\")\n",
    "\n",
    "print(f\"\\n--- Training the classification head for {INITIAL_EPOCHS} epochs ---\")\n",
    "training_start_time_total = time.time()\n",
    "for epoch in range(INITIAL_EPOCHS):\n",
    "    epoch_start_time = time.time()\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer_head, DEVICE)\n",
    "    val_loss, val_acc, _, _, _ = validate_model(model, val_loader, criterion, DEVICE)\n",
    "    epoch_end_time = time.time()\n",
    "    print(f\"Epoch {epoch+1}/{INITIAL_EPOCHS} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Time: {(epoch_end_time - epoch_start_time):.2f}s\")\n",
    "    history['train_loss'].append(train_loss); history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss); history['val_acc'].append(val_acc)\n",
    "    scheduler_head.step(val_loss)\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path_head)\n",
    "        print(f\"Epoch {epoch+1}: New best head model saved with Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "model.load_state_dict(torch.load(best_model_path_head))\n",
    "\n",
    "\n",
    "total_training_time = time.time() - training_start_time_total\n",
    "print(f\"Total training finished. Time: {total_training_time:.2f}s. Best Val Acc: {best_val_acc:.4f}\")"
   ],
   "id": "7143e5718b8c8e74",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m criterion = \u001B[43mnn\u001B[49m.CrossEntropyLoss()\n\u001B[32m      2\u001B[39m optimizer_head = optim.Adam(model.fc.parameters(), lr=INITIAL_LEARNING_RATE)\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# scheduler_head = optim.lr_scheduler.ReduceLROnPlateau(optimizer_head, mode='min', factor=0.1, patience=3, verbose=True)\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'nn' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluate Results Properly\n",
    "print(f\"\\nLoading best model from {best_model_path_head} for final evaluation.\")\n",
    "model.load_state_dict(torch.load(best_model_path_head))\n",
    "\n",
    "# Loss and Accuracy Plots (current Matplotlib code is fine)\n",
    "epochs_range_total = range(1, len(history['train_loss']) + 1)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range_total, history['train_loss'], label='Training Loss')\n",
    "plt.plot(epochs_range_total, history['val_loss'], label='Validation Loss')\n",
    "if INITIAL_EPOCHS < len(history['train_loss']): plt.axvline(x=INITIAL_EPOCHS, color='gray', linestyle='--', label='Start Fine-tuning')\n",
    "plt.legend(); plt.title('Loss'); plt.xlabel('Epochs'); plt.ylabel('Loss')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range_total, history['train_acc'], label='Training Accuracy')\n",
    "plt.plot(epochs_range_total, history['val_acc'], label='Validation Accuracy')\n",
    "if INITIAL_EPOCHS < len(history['train_acc']): plt.axvline(x=INITIAL_EPOCHS, color='gray', linestyle='--', label='Start Fine-tuning')\n",
    "plt.legend(); plt.title('Accuracy'); plt.xlabel('Epochs'); plt.ylabel('Accuracy')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Evaluate on Test Set\n",
    "print(\"\\nEvaluating on Test Set...\")\n",
    "test_loss, test_accuracy, y_true_test, y_pred_test, y_probs_test = validate_model(model, test_loader, criterion, DEVICE)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy (Overall): {test_accuracy:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix on Test Set:\")\n",
    "cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names_list, yticklabels=class_names_list)\n",
    "plt.title(\"Confusion Matrix (Test Set - Basic)\"); plt.ylabel('Actual'); plt.xlabel('Predicted'); plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_test, y_pred_test, target_names=class_names_list, digits=4))\n",
    "\n",
    "# Confidence Scores\n",
    "# y_probs_test contains the softmax probabilities for each class for each test sample\n",
    "print(\"\\nExample predictions with confidence scores (from test set):\")\n",
    "for i in range(min(5, len(y_true_test))): # Show first 5 examples\n",
    "    true_label = class_names_list[y_true_test[i]]\n",
    "    pred_label = class_names_list[y_pred_test[i]]\n",
    "    confidence_pred_class = y_probs_test[i][y_pred_test[i]]\n",
    "    all_class_confidences = y_probs_test[i]\n",
    "\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"  True Age Class: {true_label}\")\n",
    "    print(f\"  Predicted Age Class: {pred_label} (Confidence: {confidence_pred_class:.4f})\")\n",
    "    print(f\"  All Class Confidences: {[f'{c:.3f}' for c in all_class_confidences]}\")\n",
    "\n",
    "\n",
    "# Time and Resource Consumption\n",
    "print(f\"\\nTotal Training Time (Head + Fine-tune): {total_training_time:.2f} seconds\")\n",
    "\n",
    "# Inference time for one batch\n",
    "model.eval()\n",
    "dummy_input_batch = next(iter(test_loader))[0].to(DEVICE) # Get one batch of test data\n",
    "inf_start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    _ = model(dummy_input_batch)\n",
    "inf_end_time = time.time()\n",
    "avg_inference_time_per_batch = (inf_end_time - inf_start_time)\n",
    "avg_inference_time_per_image = avg_inference_time_per_batch / BATCH_SIZE\n",
    "print(f\"Average inference time per batch ({BATCH_SIZE} images): {avg_inference_time_per_batch:.4f} seconds\")\n",
    "print(f\"Average inference time per image: {avg_inference_time_per_image:.6f} seconds\")\n",
    "print(\"Resource Consumption: Monitor GPU/CPU utilization and memory manually (e.g., nvidia-smi or htop).\")\n"
   ],
   "id": "faabeef945a739c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b3ba5cd7d66f6900"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
